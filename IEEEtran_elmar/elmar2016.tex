\documentclass[a4paper,conference]{IEEEtran}

% this template contains common rules used for conference paper on ELMAR symposium therefore explanation of used packages/commands are not included in template
\usepackage{ifpdf}
\usepackage{cite}
\usepackage[pdftex]{graphicx}
\usepackage{array}
\usepackage{mdwmath}
\usepackage{mdwtab}
\usepackage{amssymb,latexsym}
\usepackage{stfloats}
\usepackage{amsmath}
\usepackage{subfig}

\DeclareRobustCommand*{\IEEEauthorrefmark}[1]{%
\raisebox{0pt}[0pt][0pt]{\textsuperscript{\footnotesize\ensuremath{#1}}}}

\hyphenation{op-tical net-works semi-conduc-tor}

\renewcommand\IEEEkeywordsname{Keywords}

\renewcommand{\citedash}{--} 

\begin{document}

\title{Arabic Manuscript Author Verification Using\\ 
Deep Convolutional Networks} %capitalize each word
% The template is designed so that author affiliations are not repeated each time for multiple authors of the same affiliation. Please keep your affiliations as succinct as possible (for example, do not differentiate among departments of the same organization). 
\author{\IEEEauthorblockN{
Andrei Boiarov\IEEEauthorrefmark{1},\IEEEauthorrefmark{*}
Alexander Senov\IEEEauthorrefmark{1},
Alexander Knysh\IEEEauthorrefmark{2} and
Dmitry Shalymov\IEEEauthorrefmark{1}}
\IEEEauthorblockA{\IEEEauthorrefmark{1}
Faculty of Mathematics and Mechanics, Saint Petersburg State University\\
Saint Petersburg, Russia}
\IEEEauthorblockA{\IEEEauthorrefmark{2}
Dept. of Near Eastern Studies, University of Michigan,\\
St. Petersburg State University Laboratory of Analysis and Modeling of Social Processes\\
Ann Arbor, Michigan, USA}
\IEEEauthorrefmark{*} Corresponding author: {\it andrei.boiarov@gmail.com}}

\maketitle

\begin{abstract}
This electronic document is a "live" template. The various components of your paper [title, text, heads, etc.] are already defined.
\end{abstract}

\begin{keywords}
Component; Formatting; Style; Styling; Insert
\end{keywords}

\IEEEpeerreviewmaketitle

\section{Introduction}
\label{sec:introduction}
The present study was motivated by the recent discovery by Dr. Noah Gardiner of the holograph (autograph) copy of the third volume of al-Maqrizi's famous "Description of Egypt" in the Library of the University of Michigan (Michigan Islamic MS 605) \cite{Noah}. The full title of the manuscript is "al-Mawa'iz wa-al-i'tibar fi dhikr al-khitat wa-al-athar" ("The Book of Admonitions and Lessons in the Catalogue of Territorial Divisions and Historical Monuments"; usually cited simply as al-Khitat). The manuscript was copied well after 818 A.H. (1415 C.E.) and was finished shortly after 831 (1427) by the celebrated Egyptian historian Taqi al-Din Ahmad Ibn 'Ali al-Maqrizi (d. 845/1442). It is the only known Maqrizi holograph (autograph) in the Americas. A number of elements in the codex, including the apparent age of the paper, lacunae in the text where the dates of certain events had not been filled in, and a number of marginal addenda and sewn-in inserts containing text found in the printed editions, led Dr. Gardiner to suspect that it might be a draft copy of the work. He visually collated the predominant hand of the codex and the inserts with some published images of al-Maqrizi’s hand and felt that a match was highly likely. He then sent images of the codex to Prof. Frederic Bauden of the University of Liege, the author of numerous articles on al-Maqrizi autographs. Prof. Bauden confirmed that the codex was indeed copied by al-Maqrizi himself, and was thus a holograph (autograph). He identified it as the fair copy (the author’s final version) of the third volume of al-Khitat, and thus the only fair copy of any volume of al-Khitat to have been found.

Given the importance of this discovery for the history of science (al-Maqrizi's Khitat is one of the earliest descriptions of the topography of Cairo and ancient Egyptian monuments in its environs as well as Alexandria), a cross-disciplinary team of researchers affiliated with the St. Petersburg State University (Laboratory of Analysis and Modeling of Social Processes) decided to verify Dr. Gardiner’s and Prof. Bauden’s findings by using method based on deep convolutional networks.

Previously used methods for author verification of arabic manuscript and for related fields were focused on developing of various types of features that can be obtained from a manuscript picture \cite{MBulacu}, \cite{DFecker}. In this paper we present a novel approach based on learning of deep hierarchical structure of features from the row image. This method belongs to the class of deep learning algorithms \cite{DL} and uses convolutional network \cite{CNN} for feature extraction and prediction. Deep convolution networks since 2012 year \cite{Alexnet} became the state of the art in many areas of computer vision: objects recognition, face identification, optical character recognition, object detection etc \cite{DL}.

The paper is organized as follows. In the next section is given a description of data set used in experiments. Section III contains presentation of our methodology of extracting patches from image, training deep convolution networks and making decision of manuscript author. In section IV we present results of our experiments. At the end, conclusion is given.  
%\pagebreak
	

\begin{figure*}[!t]
	\center
  \includegraphics[width=\textwidth]{figures/Al-Maqrizi_classification_pipeline.png}
  \caption{al-Maqrizi authorship soft classification pipeline}
  \label{fig:pipeline}
\end{figure*}	
	
\section{Data Set}
\label{sec:the_data}

Solving of the problem of al-Maqrizi authorship verification requires training and test data sets. As a one unique data element we consider single page of manuscript. Data set composes of a set of consistent parts from manuscripts of two kinds:
\begin{itemize}
	\item Two sets of verified al-Maqrizi's holographs from codex of Prof. Bauden is taken as a positive examples.
	\item Eight manuscripts not written by al-Maqrizi's hand from the University of Michigan Hatcher Library (Special Collections) are considered as a negative examples. This manuscripts are selected in such way that the date and place of writing each of them is close to al-Maqrizi's Khitat: 14th and 15th centuries, Egypt and Syria.
\end{itemize}
For robustness of learning process obtained data is divided into training and test sets:
\begin{itemize}
	\item Training set: 1 al-Maqrizi's manuscript consisting of 26 pages and 5 not al-Maqrizi's manuscripts each of which consists of 7 pages.
	\item Test set: 1 al-Maqrizi's manuscript consisting of 14 pages and 3 not al-Maqrizi's manuscripts each of which consists of 7 pages. Authors of this 3 manuscripts differ from authors of 5 negative examples in training set.   
\end{itemize}

It is important to note that we split our data set by the factor of a manuscript author. Thus when algorithm is learning on training set, it can not see authors in test set. In that way we achieve robustness our method in terms of manuscripts because input of method is a whole manuscript. Number of not al-Maqrizi's documents is chosen in such way that training and test set is nearly balanced.

Main interest of this paper is author verification of al-Khitat manuscript consisting of 32 pages.


%\pagebreak

\section{Method}
\label{sec:the_method}

We consider author verification problem as a binary classification problem: al-Maqrizi class denoted as $1$ and non al-Maqrizi class denoted as $0$. In this context our goal is to build a classification pipeline able predict the probability (\textit{soft} classification) that given image belongs to the $1$ (al-Maqrizi) class. The entire al-Maqrizi authorship classification pipeline illustrated at figure~\ref{fig:pipeline} consists of the following steps:

\begin{enumerate}[start=0]
	\item Image preprocessing.
	\item Extracting patches from candidate image.
	\item Patches soft classification using convolution network.
	\item Averaging predicted patches probabilities to produce overall candidate image al-Maqrizi authorship probability.
\end{enumerate}

Each of this steps are thoroughly described in the following sections.	

%The heart of our method is a \convnet patches classifier. We use ground-truth labelled patches extracted from images described in section~\ref{sec:the_data} as a training set for \convnet. [SOME DEFERRABLES FOR \convnet HERE].


\subsection{Image preprocessing}
This step was done to bring all images to relatively same size and scale by performing following steps:
\begin{enumerate}
	\item Removing part of image within the text bounding box.
	\item Resizing resulted image to resolution $700\times 500$.
\end{enumerate}
This steps are reasonable enough since all images from our data set has approximately equal number of text lines and text bounding box aspect ratio. 

Since this step is done only to unify our image data set we does not include it in the pipeline.

\subsection{Patches extraction}
The patches extraction method generates a set of sub-images called patches from given image. The basic idea is that patch should represent small but yet meaningful part of image for the main purpose - authorship verification. We use two alternative methods for patches extraction described in following subsections.

\subsubsection{Sliding window based method}
This method splits image into patches by a grid of fixed cell of size $80\times 80$ pixels with a stride $20$ pixels. Figure~\ref{fig:patches_example_sliding_window} illustrates the idea. 

\subsubsection{Connected components based method}
This method uses following routine for patches extraction

\begin{enumerate}
	\item Input image binarization using Otsu's filter~\cite{otsu1975threshold}.
	\item Connected components extraction from binarized image using algorithm from~\cite{fiorio1996connected_components}.
	\item Too small, too big and too stretched connected components filtering using several empirical rules, e.g.: major axis to minor axis ratio less then $10$, minimum minor axis length greater then $3$ pixels, etc.
	\item Outlier connected components filtering using DBSCAN clustering algorithm~\cite{ester1996dbscan}.
	\item Extracting remaining connected components bounding boxes from source image and resizing them $28\times 28$ pixels size.
\end{enumerate}

Example of connected components based patches show on figure~\ref{fig:patches_example_connected_components}. 

It could be seen, that connected components based patches usually consist of one or few letters thus providing high robustness for different image scale and size in contrast to fixed-size sliding window patches. However, fixed-sliding patches contain much more information: several symbols from several lines, --- a very important feature for the authorship verification.
%
%\begin{figure}[!b]
%    \centering
%    \includegraphics[width=0.2\textwidth]{figures/patches_example_connected_components.png}	 
%	\hfill    
%    \includegraphics[width=0.2\textwidth]{figures/patches_example_connected_components.png} 
%%    \caption{2 Figures side by side}%
%    \label{fig:example}%
%\end{figure}

%\begin{figure}
%	\centering
%	\begin{minipage}{0.1\textwidth}
%	\centering
%	\includegraphics{figures/patches_example_connected_components.png}
%	\caption{first figure}
%	\end{minipage}
%	\hfill
%	\begin{minipage}{0.1\textwidth}
%	\centering
%	\includegraphics{figures/patches_example_connected_components.png}
%	\caption{second figure}
%	\end{minipage}
%\end{figure}

\begin{figure}
\centering
\begin{minipage}{.30\linewidth}
  \includegraphics[width=\linewidth]{figures/3.png}
  \captionof{figure}{Sliding window patches example figure}
  \label{img1}
\end{minipage}
\hspace{.05\linewidth}
\begin{minipage}{.30\linewidth}
  \includegraphics[width=\linewidth]{figures/patches_example_connected_components.png}
  \captionof{figure}{Connected components patches example}
  \label{img2}
\end{minipage}
\end{figure}

%\begin{figure}
%	\centering
%	\subcaptionbox{A cat\label{cat}}
%	[.4\linewidth]{\includegraphics{figures/patches_example_connected components.png}}%
%	\subcaptionbox{An elephant\label{elephant}}
%	[.4\linewidth]{\includegraphics{figures/patches_example_connected components.png}}
%	\caption{Two animals}\label{animals}
%\end{figure}

\subsection{Deep convolution network}

Denote $x_i$ as the $i$-th patch obtained from image in the previous step and $y_i$ as binary label. Then for predicting the probability
\begin{equation*}
	p_i = P(y_i | x_i)
\end{equation*}
that current patch belongs to al-Maqrizi's hand we need to train a discriminative model. As a robust and powerful classification algorithm deep convolution networks \cite{DL}, \cite{CNN} are chosen. 

In a case of sliding window patches we apply Alexnet type of network \cite{Alexnet}. Architecture of this network described in table~\ref{alexnet_tab}.
\begin{table}[!h]
\centering
\caption{Sliding window patch convolution network}
\label{alexnet_tab}
\begin{tabular}{|l|p{1.3cm}|p{1.3cm}|}
\hline
\textbf{type} & \textbf{patch size/ stride} & \textbf{output number}  \\
\hline
convolution & 11 / 4 & 96 \\
\hline
local response norm & & 96 \\
\hline
max pool & 3 / 2 & 96 \\
\hline
convolution & 5 / 1 & 256 \\
\hline
local response norm & & 256 \\
\hline
max pool & 3 / 2 & 256 \\
\hline
convolution & 3 / 1 & 384 \\
\hline
convolution & 3 / 1 & 384 \\
\hline
convolution & 3 / 1 & 256 \\
\hline
max pool & 3 / 2 & 256 \\
\hline
fully connected & & 4096 \\
\hline
dropout (50 \%) & & 4096 \\
\hline
fully connected & & 4096 \\
\hline
dropout (50 \%) & & 4096 \\
\hline
fully connected & & 2 \\
\hline
softmax & & 2 \\
\hline
\end{tabular}
\end{table}

As an input network takes $80\times80$ RGB image. All activation functions in convolution and fully connected layers is rectified linear units (ReLU). This deep network was trained by stochastic gradient descent method with Nesterov momentum, initial learning rate is $0.01$ and it decrease policy is step down.

With connected components patches we use GoogLeNet type of deep convolutional network \cite{Googlenet}. It architecture provided in table~\ref{googlenet_tab}. 
\begin{table}[!h]
\centering
\caption{Connected components patch convolution network}
\label{googlenet_tab}
\begin{tabular}{|l|p{1.3cm}|p{1.3cm}|}
\hline
\textbf{type} & \textbf{patch size/ stride} & \textbf{output number}  \\
\hline
convolution & 7 / 2 & 64 \\
\hline
max pool & 3 / 2 & 64 \\
\hline
local response norm & & 64 \\
\hline
convolution & 1 / 1 & 64 \\
\hline
convolution & 3 / 1 & 192 \\
\hline
local response norm & & 192 \\
\hline
max pool & 3 / 2 & 192 \\
\hline
inception &  & 256 \\
\hline
inception &  & 480 \\
\hline
max pool & 3 / 2 & 480 \\
\hline
inception &  & 512 \\
\hline
convolution & 1 / 1 & 128 \\
\hline
fully connected & & 1024 \\
\hline
dropout (70 \%) & & 1024 \\
\hline
fully connected & & 2 \\
\hline
softmax & & 2 \\
\hline
\end{tabular}
\end{table}

As an input network takes $28\times28$ RGB image. All activation functions in convolution and fully connected layers is rectified linear units (ReLU). Inception layer is a combination of several convolution and pooling layers, for more details see \cite{Googlenet}. Learning method for this convolutional network is stochastic gradient descent with Nesterov momentum and initial learning rate $0.01$ with step down decrease policy. 

\section{Results and Discussion}

We experimented with both types of patches extraction and corresponding convolutional networks. 

\subsection{Deep convolutional network learning}

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.2]{figures/alexnet_loss.png}
\caption{Sliding window patch convolution network learning process.}
\label{img_alexnet}
\end{figure}

In picture~\ref{img_alexnet} displayed values of loss function on training (blue curve) and test (green curve) sets depending on the learning epoch for sliding window patch convolution network. Also one can see accuracy (orange curve) on test set. It final value is near $87 \%$. For connected components patch convolution network accuracy is worse --- $80 \%$.    

\subsection{Manuscript classification}

To assess quality of the classification pipeline we use only images from the test set, since they are the only ones had not been used in the learning process. 

Figure~\ref{fig:al_maqrizi_classification_example} demonstrates classification result for two images from the test set: one from al-Maqrizi class and one from not al-Maqrizi class. As you can see, both of them classified quite confidently with estimated al-Maqrizi authorship probability $0.0085$ and $0.94$ respectively. Also this figure shows classification result for Khitat manuscript page. It gives $0.77$ probability of al-Maqrizi authorship.

\begin{figure}
\centering
\begin{minipage}{.48\linewidth}
	\centering
  \includegraphics[width=\linewidth]{figures/not_al_maqrizi_image_classification_example.png}
  %\captionof{figure}{ }
  %\label{fig:}
\end{minipage}
\hspace{.01\linewidth}
\begin{minipage}{.48\linewidth}
	\centering
  \includegraphics[width=\linewidth]{figures/sw_al_maqrisi.png}
  %\captionof{figure}{ }
  %\label{fig:}
\end{minipage}
\hspace{.01\linewidth}
\begin{minipage}{.48\linewidth}
	\centering
  \includegraphics[width=\linewidth]{figures/hitat_15.png}
  %\captionof{figure}{ }
  %\label{fig:}
\end{minipage}
  \captionof{figure}{Sliding window patches al-Maqrizi authorship classification example: not al-Maqrizi manuscript page (left), al-Maqrizi manuscript page (right) and manuscript page from Khitat (down). Patches probabilities visualized using white-red (corresponding to 0-1 classes) colors on top of the original image. Additionally, probabilities histogram presented below.}
	\label{fig:al_maqrizi_classification_example}
\end{figure}

Regarding entire test set classification for sliding window patches with decision threshold $0.5$ we obtained precision $0.99$ and recall $0.92$. Method based on connected components patches is less robust: it generate many false positive predictions. But this approach has great potential and for it stable work required much more training examples. Thus convolutional network learned on connected components patches is prominent field for further research.

By using sliding window patches with deep network method we received that mean probability of al-Maqrizi authorship of Khitat is equal $0.86$.    

\section{Conclusion}

The join research on al-Maqrizi’s "Description of Egypt" undertaken by a historian-philologist and three mathematicians from St. Petersburg State University is a unique experiment in working across disciplinary boundaries to achieve a common goal. Its results bode well for the future by opening new horizons for scholars of "Oriental" manuscripts who often desperately lack resources (other than their own eyes and intuition) to verify the provenance and authorship of the manuscript material they are working with. Given the propensity of Muslim scribes and later writers to attribute manuscripts to important luminaries of the past (such as, e.g., al-Ghazali, d. 505/1111; Ibn al-Arabi, d. 638/1240, and others), the new methods of analyzing and verifying handwritten texts, which have been designed and tested by St. Petersburg mathematicians, are bound to become an important tool for their colleagues in the humanities and social sciences.

\section*{Acknowledgment}

This research is supported by Saint Petersburg State University grant 6.37.181.2014. The authors express their deep gratitude to Mrs. Evyn Kropf of the Hatcher Graduate Library who kindly facilitated access to the University of Michigan library resources.

% Refer simply to the reference number, as in [3]—do not use "Ref. [3]" or "reference [3]" except at the beginning of a sentence: "Reference [3] was the first . . ." Unless there are six authors or more give all authors' names; do not use "et al.". Papers that have not been published, even if they have been submitted for publication, should be cited as "unpublished" [4]. Papers that have been accepted for publication should be cited as "in press" [5]. Capitalize only the first word in a paper title, except for proper nouns and element symbols. For papers published in translation journals, please give the English citation first, followed by the original foreign-language citation [6].
% All references should be cited in text.
\bibliographystyle{ieeetr} 
\bibliography{reference}

\end{document}




