\documentclass[conference,a4paper]{ieeetran}

\usepackage[latin1]{inputenc}
\usepackage{subeqnarray}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{color}
\parskip 1mm
\arraycolsep 0.5mm
\newtheorem{theorem}{Theorem}
\newcommand{\sign}{\mathrm{sign}}
\newcommand{\sat}{\mathrm{sat}}

\title{Arabic Manuscript Author Verification Using\\ 
Deep Convolutional Networks}

\author{\authorblockN{Andrei Boiarov\authorrefmark{1}, Alexander Senov\authorrefmark{1} and Alexander Knysh\authorrefmark{2}\authorrefmark{3} }
\authorblockA{\authorrefmark{1} Faculty of Mathematics and Mechanics, Saint Petersburg State University, Saint Petersburg, Russia\\
e-mail: andrei.boiarov@gmail.com, alexander.senov@gmail.com}
\authorblockA{\authorrefmark{2} Department of Near Eastern Studies, University of Michigan, Ann Arbor, Michigan, USA\\}
\authorblockA{\authorrefmark{3} Research Laboratory for Analysis and Modeling of Social Processes, St. Petersburg State University, St. Petersburg, Russia\\ 
e-mail: alknysh@umich.edu}}

\begin{document}
\maketitle
\begin{abstract}
In this paper, we propose an automatic method for manuscript author verification based on an analysis of consecutive patches extracted from an image. The classification algorithm uses a deep convolutional network with two types of patch extraction: one based on connected components and the other based on usage of a fixed-size sliding window. We apply this method to verify the authorship of the Arabic manuscript entitled \textit{al-Khitat} attributed to the hand of the renowned  medieval Arab historian al-Maqrizi. Using appropriately collected ground-truth labeled data for convolutional network training purpose our method has demonstrated promising results when applied to previously unseen manuscripts.
\end{abstract}

\begin{keywords}
    Author verification, Convolutional networks, Deep learning, Handwriting recognition, Historical Arabic manuscript.
\end{keywords}

\section{Introduction}
\label{sec:introduction}
The problem of manuscript author verification is quite important nowadays. Since manual verification has a subjectivity drawback, the solution requires objective automatic methods. The present study was motivated by the recent discovery by Dr. Noah Gardiner of the holograph (autograph) copy of the third volume of al-Maqrizi's famous ``Description of Egypt'' in the Library of the University of Michigan \cite{Noah}. The full title of the manuscript is ``The Book of Admonitions and Lessons in the Catalogue of Territorial Divisions and Historical Monuments''; usually cited as \textit{al-Khitat}. The manuscript was finished shortly after 831 A.H. (1427 C.E.) by the celebrated Egyptian historian Taqi al-Din Ahmad Ibn 'Ali al-Maqrizi (d. 845/1442). In his paper, Dr. Gardiner made the assumption that it might be a draft copy of the work. He then sent images of the codex to Prof. Frederic Bauden of the University of Liege, the author of numerous articles on al-Maqrizi autographs. Buaden identified it as the fair copy (the author's final version) of the third volume of \textit{al-Khitat}, and thus the only fair copy of any volume of \textit{al-Khitat} to have been found.

Given the importance of this discovery for the history of science (al-Maqrizi's \textit{al-Khitat} is one of the earliest descriptions of the topography of Cairo and ancient Egyptian monuments in its environs as well as Alexandria), authors decided to verify Dr. Gardiner's and Prof. Bauden's findings using method based on deep convolutional networks.

Previously used methods for author verification of Arabic manuscript and for related fields were focused on developing various types of features that can be obtained from a manuscript picture. These features are then used to learn a classification model. Here are some of the approaches: textural, allographic features and clustering methods \cite{MBulacu}, \cite{MBulacu1}; contour-based, oriented basic image, K-SIFT features and SVM \cite{DFecker}, texture-related and structure-related features \cite{Salvador}, TF/IDF and clustering algorithms \cite{Dunn}. In this paper, we present a novel approach based on learning of deep hierarchical structure of features from the row image. This method belongs to the class of the deep learning algorithms \cite{DL} and uses convolutional network \cite{CNN} for feature extraction and prediction. Deep convolution networks since 2012 year \cite{Alexnet} became the state of the art in many areas of computer vision: objects recognition, face identification, optical character recognition, object detection, etc \cite{DL}. Deep learning approach is based on using artificial neural networks with a huge number of layers which allows to train deep hierarchical representation of data. This representation in many cases works better then handmade features \cite{DL}, \cite{Alexnet}, \cite{Googlenet}. Moreover deep networks are not saturate with an increasing amounts of data thus they have better generalization ability then traditional ``shalow'' methods like logistic regeression or SVM \cite{DL}.   

The paper is organized as follows. In Section~\ref{sec:the_data}, a description of the data set used in experiments is given. Section~\ref{sec:the_method} contains presentation of our methodology of patches from image extraction, training deep convolution networks and making decision of manuscript author. In Section~\ref{sec:results_and_description}, we present the results of our experiments.
%\pagebreak
	

\begin{figure*}[!t]
	\center
  \includegraphics[width=0.9\textwidth]{figures/Al-Maqrizi_classification_pipeline.png}
  \caption{al-Maqrizi authorship classification pipeline}
  \label{fig:pipeline}
\end{figure*}	
	
\section{Data Set}
\label{sec:the_data}

Solving the problem of al-Maqrizi authorship verification requires training and test data sets. 
We consider a single page of the manuscript as one data unit.
As a one unique data element we consider single page of manuscript. The data set consists of two sets of manuscript materials:
\begin{itemize}
	\item two holographs of al-Maqrizi verified by Prof. Bauden will serve as a positive example;
	\item eight manuscripts not written by al-Maqrizi's hand  (taken from the University of Michigan Hatcher Library Special Collections) are considered to be a negative example. These manuscripts were selected in such a way that the date and place of writing of each of them would be close to those of al-Maqrizi's  \textit{al-Khitat}, namely, the 14th and 15th centuries, Egypt and Syria.
\end{itemize}

To enhance robustness of the learning process the data obtained were divided into training and test sets:
\begin{itemize}
	\item Training set: 1 al-Maqrizi's manuscript consisting of 26 pages and 5 not al-Maqrizi's manuscripts each of which consists of 7 pages.
	\item Test set: 1 al-Maqrizi's manuscript consisting of 14 pages and 3 non-al-Maqrizi's manuscripts each of which consists of 7 pages. Authors of these 3 manuscripts differ from authors of 5 negative examples in the training set.   
\end{itemize}

It is important to note that we split our data set by the factor of the manuscript author. When the algorithm is learning on the training set, it can not see the authors in the test set. Thus, we enforce our method to infer general properties al-Maqrizi's handwriting not specific for particular manuscript. Number of non-al-Maqrizi's documents is chosen in such way that positive and negative classes in training and test sets are roughly balanced.

The goal of this study is to verify the authorship of the \textit{al-Khitat} manuscript that consists of 32 pages.


%\pagebreak

\section{Method}
\label{sec:the_method}

We consider author verification as a binary classification problem: the al-Maqrizi class designated as 1 and the non-al-Maqrizi class designated as 0. In this context our goal is to build a classification pipeline able to predict the probability (\textit{soft} classification) that a given image belongs to the $1$ (al-Maqrizi) class. The entire al-Maqrizi authorship classification pipeline illustrated at Figure~\ref{fig:pipeline} consists of the following steps:

\begin{enumerate}
	\item Image preprocessing.
	\item Extracting patches from candidate image.
	\item Soft classification of patches using convolution network.
	\item Averaging predicted patches probabilities to produce overall candidate image of the probability of al-Maqrizi's authorship.
\end{enumerate}

Each of these steps are thoroughly described in the following sections.	


\subsection{Image preprocessing}
This step was done to bring all images to relatively same size and scale by performing the following steps:
\begin{enumerate}
	\item Removing part of image within the text bounding box.
	\item Resizing resulted image to resolution $700\times 500$.
\end{enumerate}
This steps are reasonable enough since all images from our data set have approximately equal number of text lines and text bounding box aspect ratio. 

Since this step is done only to unify our images data set we do not include it in the pipeline.

\subsection{Patches extraction}
The patches extraction method generates a set of sub-images called patches from a given image. The basic idea is that a patch should represent a small but yet meaningful part of image for the purpose of authorship verification. We use two alternative methods for patches extraction described in following subsections.

\subsubsection{Sliding window based method}
This method splits an image into patches by a grid of fixed cells of the size $80\times 80$ pixels with a stride $20$ pixels. Figure~\ref{fig:patches_example_sliding_window} illustrates the idea. 

\subsubsection{Connected components-based method}
This method uses the following routine for patches extraction

\begin{enumerate}
	\item Input image binarization using Otsu's filter~\cite{otsu1975threshold}.
	\item Connected components extraction from a binarized image using the algorithm from~\cite{fiorio1996connected_components}.
	\item Too small, too big and too stretched connected components filtering using several empirical rules, e.g.: major axis to minor axis ratio less then $10$, minimum minor axis length greater then $3$ pixels, etc.
	\item Outlier connected components filtering using the\\ DBSCAN clustering algorithm~\cite{ester1996dbscan}, \cite{GranVolk}.
	\item Extracting remaining connected components bounding boxes from the source image and resizing them $28\times 28$ pixels size.
\end{enumerate}

Example of connected components based patches show on Figure~\ref{fig:patches_example_connected_components}. 

As one can see, connected components-based patches usually consist of one or few letters thus providing a high robustness for different image scale and size in contrast to fixed-size sliding window patches (since all images been preprocessed this features is not important in our case). However, sliding-window patches contain much more information: several symbols from multiple lines --- a very important feature for authorship verification.
%
%\begin{figure}[!b]
%    \centering
%    \includegraphics[width=0.2\textwidth]{figures/patches_example_connected_components.png}	 
%	\hfill    
%    \includegraphics[width=0.2\textwidth]{figures/patches_example_connected_components.png} 
%%    \caption{2 Figures side by side}%
%    \label{fig:example}%
%\end{figure}

%\begin{figure}
%	\centering
%	\begin{minipage}{0.1\textwidth}
%	\centering
%	\includegraphics{figures/patches_example_connected_components.png}
%	\caption{first figure}
%	\end{minipage}
%	\hfill
%	\begin{minipage}{0.1\textwidth}
%	\centering
%	\includegraphics{figures/patches_example_connected_components.png}
%	\caption{second figure}
%	\end{minipage}
%\end{figure}

\begin{figure}[!t]
\centering
\begin{minipage}{.45\linewidth}
	\centering
  \includegraphics[height=.7\linewidth]{figures/3.png}
  \caption{Sliding window patch example}
  \label{fig:patches_example_sliding_window}
\end{minipage}
\hspace{.05\linewidth}
\begin{minipage}{.45\linewidth}
	\centering
  \includegraphics[height=.7\linewidth]{figures/patches_example_connected_components_part.png}
  \caption{Connected components patches example}
  \label{fig:patches_example_connected_components}
\end{minipage}
\end{figure}

%\begin{figure}
%	\centering
%	\subcaptionbox{A cat\label{cat}}
%	[.4\linewidth]{\includegraphics{figures/patches_example_connected components.png}}%
%	\subcaptionbox{An elephant\label{elephant}}
%	[.4\linewidth]{\includegraphics{figures/patches_example_connected components.png}}
%	\caption{Two animals}\label{animals}
%\end{figure}

\subsection{Deep convolution network}

Denote $x_i$ as the $i$-th patch obtained from an image in the previous step and $y_i$ as binary label. Then for predicting the probability
\begin{equation*}
	p_i = P(y_i | x_i)
\end{equation*}
that the current patch belongs to al-Maqrizi's hand we need to train a discriminative model. As a robust and powerful classification algorithm deep convolution networks \cite{DL}, \cite{CNN} are chosen. 

In a case of sliding window patches we apply Alexnet type of network \cite{Alexnet}. Its architecture and layers parameters is described in Table~\ref{alexnet_tab}. This table contains the following columns: layer type, patch size and stride parameters for convolutional and pooling layers, number of layer output neurons.  
\begin{table}[!b]
\centering
\caption{Sliding window patch convolution network}
\label{alexnet_tab}
\begin{tabular}{|l|p{1.3cm}|p{1.3cm}|}
\hline
\textbf{layer type} & \textbf{patch size/ stride} & \textbf{output number}  \\
\hline
convolution & 11 / 4 & 96 \\
\hline
local response norm & & 96 \\
\hline
max pool & 3 / 2 & 96 \\
\hline
convolution & 5 / 1 & 256 \\
\hline
local response norm & & 256 \\
\hline
max pool & 3 / 2 & 256 \\
\hline
convolution & 3 / 1 & 384 \\
\hline
convolution & 3 / 1 & 384 \\
\hline
convolution & 3 / 1 & 256 \\
\hline
max pool & 3 / 2 & 256 \\
\hline
fully connected & & 4096 \\
\hline
dropout (50 \%) & & 4096 \\
\hline
fully connected & & 4096 \\
\hline
dropout (50 \%) & & 4096 \\
\hline
fully connected & & 2 \\
\hline
softmax & & 2 \\
\hline
\end{tabular}
\end{table}

\begin{figure}[!b]
	\centering
  \includegraphics[width=0.49\linewidth]{figures/tmp.png}
  %\captionof{figure}{ }
  %\label{fig:}
%  \captionof{figure}{Sliding window patches al-Maqrizi authorship classification example: %non-al-Maqrizi manuscript page (left), al-Maqrizi manuscript page (right) the transcript %page from {\it al-Khitat} (bottom). Patches probabilities are visualized by using white-%red colors (corresponding to 0-1 classes) on the top of the original image. Additionally, %a probabilities histogram is shown below.}
\end{figure}

As an input network takes $80\times80$ RGB image. All activation functions in convolution and fully connected layers are rectified linear units (ReLU). This deep network was trained by stochastic gradient descent method with Nesterov momentum, initial learning rate is $0.01$ and it decrease policy is step down.

With connected components patches we use GoogLeNet type of deep convolutional network \cite{Googlenet}. Its architecture and layers parameters is provided in Table~\ref{googlenet_tab}.
\begin{table}[!t]
\centering
\caption{Connected components patch convolution network}
\label{googlenet_tab}
\begin{tabular}{|l|p{1.3cm}|p{1.3cm}|}
\hline
\textbf{layer type} & \textbf{patch size/ stride} & \textbf{output number}  \\
\hline
convolution & 7 / 2 & 64 \\
\hline
max pool & 3 / 2 & 64 \\
\hline
local response norm & & 64 \\
\hline
convolution & 1 / 1 & 64 \\
\hline
convolution & 3 / 1 & 192 \\
\hline
local response norm & & 192 \\
\hline
max pool & 3 / 2 & 192 \\
\hline
inception &  & 256 \\
\hline
inception &  & 480 \\
\hline
max pool & 3 / 2 & 480 \\
\hline
inception &  & 512 \\
\hline
convolution & 1 / 1 & 128 \\
\hline
fully connected & & 1024 \\
\hline
dropout (70 \%) & & 1024 \\
\hline
fully connected & & 2 \\
\hline
softmax & & 2 \\
\hline
\end{tabular}
\end{table}

\begin{figure*}[!t]
	\center
  \includegraphics[width=0.9\textwidth]{figures/tmp_1.png}
\end{figure*}	

As an input network takes $28\times28$ RGB image. All activation functions in convolution and fully connected layers are rectified linear units (ReLU). Inception layer is a combination of several convolution and pooling layers; for more details see \cite{Googlenet}. Learning method for this convolutional network is stochastic gradient descent with Nesterov momentum and initial learning rate $0.01$ with step down decrease policy. 

\section{Results and Discussion}
\label{sec:results_and_description}

We have experimented with both types of patches extraction and corresponding convolutional networks. 

\subsection{Deep convolutional network learning}

%\begin{figure}[!ht]
%\centering
%\includegraphics[scale=0.22]{figures/alexnet_loss.png}
%\caption{Sliding window patch convolution network learning process.}
%\label{img_alexnet}
%\end{figure}

Deep artificial networks have been trained with backpropagation algorithm \cite{CNN} and shown small training error. For sliding window patch convolution network accuracy value on the test set is near $87 \%$. For connected components patch convolution network accuracy is worse --- $80 \%$.    

\subsection{Manuscript classification}

To assess quality of the classification pipeline we have used only images from the test set, since they are the only ones not used in the learning process. 

Figure~\ref{fig:al_maqrizi_classification_example_train} demonstrates the classification results for two images from the test set: one from al-Maqrizi class and one from non-al-Maqrizi class. As one can see, both of them can be classified quite confidently as having al-Maqrizi as the author with the probability $0.0085$ and $0.94$ respectively. Figure~\ref{fig:al_maqrizi_classification_example_test_hitat} shows the classification result for an {\it al-Khitat} manuscript page. It gives $0.77$ probability of al-Maqrizi being the author.

\begin{figure}[!t]
	\centering
  \includegraphics[width=0.49\linewidth]{figures/not_al_maqrizi_image_classification_example_fixed.png}
  \includegraphics[width=0.49\linewidth]{figures/sw_al_maqrisi_fixed.png}
  \caption{Sliding window patches al-Maqrizi authorship classification example visualization on non-al-Maqrizi manuscript page (left) and al-Maqrizi manuscript page (right). Patches probabilities are visualized by using white-red colors (corresponding to 0-1 classes) on the top of the original image. Average al-Maqrizi authorship probability across patches is 0.0085 and 0.94 respectively.}
	\label{fig:al_maqrizi_classification_example_train}
\end{figure}


\begin{figure}[!b]
	\centering
  \includegraphics[width=0.49\linewidth]{figures/hitat_15_fixed.png}
   \caption{Sliding window patches al-Maqrizi authorship classification example visualization on the page from {\it al-Khitat} manuscript. Average al-Maqrizi authorship probability across patches is 0.77.}
  %\captionof{figure}{ }
  %\label{fig:}
%  \captionof{figure}{Sliding window patches al-Maqrizi authorship classification example: %non-al-Maqrizi manuscript page (left), al-Maqrizi manuscript page (right) the transcript %page from {\it al-Khitat} (bottom). Patches probabilities are visualized by using white-%red colors (corresponding to 0-1 classes) on the top of the original image. Additionally, %a probabilities histogram is shown below.}
	\label{fig:al_maqrizi_classification_example_test_hitat}
\end{figure}

Regarding the entire test set classification for sliding window patches with decision threshold $0.5$ we obtained precision $0.99$ and recall $0.92$. The method based on connected components patches is less robust: it generates many false positive predictions. This approach has a great potential, however, its improvement requires many more training examples. In sum, convolutional network learned on connected components patches is a promising field for further research.

By using sliding window patches with deep network method we have arrived at the conclusion that the mean probability of al-Maqrizi's authorship  of the entire set of the {\it al-Khitat} pages equals $0.86$.    

\section{Conclusion}

Deep convolutional network with sliding window patches demonstrates very prominent result in resolving the problem of the authorship of {\it al-Khitat}. In comparison with other methods \cite{MBulacu}, \cite{MBulacu1}, \cite{DFecker}, \cite{Salvador} our approach shows a positive outcome without the need to construct complex features. To apply this method to other Arabic authors, we will train our network on a larger volume of data. The joint study of al-Maqrizi's ``Description of Egypt'' undertaken by a historian-philologist and mathematicians is a unique experiment in working across disciplinary boundaries to achieve a common goal. The results obtained thus far bode well for the future by opening new horizons for scholars of ``Oriental'' manuscripts who often desperately lack resources (other than their own eyes and intuition) to verify the provenance and authorship of the manuscript material they are working with.

\section*{Acknowledgment}
 This research is supported by Saint Petersburg State University grant 6.37.181.2014. The authors express their deep gratitude to Mrs. Evyn Kropf of the Hatcher Graduate Library who kindly facilitated access to the University of Michigan library resources.
 
 \begin{thebibliography}{99}

\bibitem{Noah} N.~Gardiner, F.~Bauden, \lq\lq A Recently Discovered Holograph Fair Copy of al-Maqrizi's al-Mawa'iz wa-al-i'tibar fi dhikr al-khitat wa-al-athar (Michigan Islamic MS 605),\rq\rq~in~\emph{Journal of Islamic Manuscripts}, vol.~2, E.~J.~Brill, Leiden and Boston, 2011, pp.~123--131.

\bibitem{MBulacu} M.~Bulacu, L.~Schomaker, A.~Brink, \lq\lq Text-independent writer identification and verification on offline arabic handwriting,\rq\rq~in~\emph{Proc. 9th International Conference on Document Analysis and Recognition, ICDAR}, Curitiba, 2007, pp.~769--773.

\bibitem{MBulacu1} M.~Bulacu, L.~Schomaker, \lq\lq Automatic Handwriting Identification on Medieval Documents,\rq\rq~in~\emph{Proc. of the International Conference on Image Analysis and Processing}, Modena, 2007, pp.~279--284.

\bibitem{DFecker} D.~Fecker, A.~Asi, W.~Pantke, V.~Margner, J.~El-Sana, T.~Fingscheidt, \lq\lq Document Writer Analysis with Rejection for Historical Arabic Manuscripts,\rq\rq~in~\emph{Proc. 14th nternational Conference on Frontiers in Handwriting Recognition, ICFHR}, Crete, 2014, pp.~743--748.

\bibitem{Salvador} S.~Godoy-Calderon, E.~M.~Felipe-Riveron, E.~C.~Herrera-Luna, \lq\lq Multi-level Modeling of Manuscripts for Authorship Identification with Collective Decision Systems,\rq\rq~\emph{Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications}, vol.~7441, pp.~757--764, 2012.

\bibitem{Dunn} E.~Dunn, \lq\lq Computational Methods for Determining the Similarity between Ancient Greek Manuscripts,\rq\rq Master of Science~thesis, Dept.~Computer~Science., Dept.~Inform.~Systems~and~Operations~Manag. Univ.~of North Carolina, Wilmington, 2012.

\bibitem{DL} Y.~Lecun, Y.~Bengio, G.~Hinton, \lq\lq Deep learning,\rq\rq~\emph{Nature}, no.~521, pp.~436--444, May.~2015.

\bibitem{CNN} Y.~Lecun, L.~Bottou, Y.~Bengio, P.~Haffner, \lq\lq Gradient-based learning applied to document recognition,\rq\rq~in~\emph{Proc. of the IEEE}, 1998, pp.~2278--2324.

\bibitem{Alexnet} A.~Krizhevsky,I.~Sutskever, G.~Hinton, \lq\lq ImageNet Classification with Deep Convolutional Neural Networks,\rq\rq~in~\emph{Advances in Neural Information Processing Systems}, vol.~25, 2012, pp.~1097--1105.

\bibitem{Googlenet} C.~Szegedy, W.~Liu, Y.~Jia, P.~Sermanet, S.~Reed, D.~Anguelov, D.~Erhan, V.~Vanhoucke, A.~Rabinovich, \lq\lq Going deeper with convolutions,\rq\rq~in~\emph{Proc. of the IEEE Conference on Computer Vision and Pattern Recognition}, Boston, 2015, pp.~1--9.

\bibitem{otsu1975threshold} N.~Otsu, \lq\lq A threshold selection method from gray-level histograms, \rq\rq~\emph{Automatica}, vol.~11, 1975, pp.~285--296.

\bibitem{fiorio1996connected_components} C.~Fiorio, J.~Gustedt, \lq\lq Two linear time union-find strategies for image processing, \rq\rq~\emph{Theoretical Computer Science}, vol.~154, no.~2, 1996, pp.~165--181.

\bibitem{ester1996dbscan} M.~Ester, H.P.~Kriegel, J.~Sander, X.~Xu, \lq\lq A density-based algorithm for discovering clusters in large spatial databases with noise, \rq\rq~in~\emph{Proc. of Second International
Conference on Knowledge Discovery and Data Mining}, vol.~96, no.~34, 1996, pp.~226--231.

\bibitem{GranVolk} O.~Granichin, V.~Volkovich, D.~Toledano-Kitai, \emph{Randomized Algorithms in Automatic Control and Data Mining}. Springer-Verlag: Heidelberg, New York, Dordrecht, London, 2015, 251~p.

\end{thebibliography}

\end{document}